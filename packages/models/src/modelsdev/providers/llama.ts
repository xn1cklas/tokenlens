export const llamaProvider = {
  id: "llama",
  name: "Llama",
  api: "https://api.llama.com/compat/v1/",
  npm: "@ai-sdk/openai-compatible",
  doc: "https://llama.developer.meta.com/docs/models",
  env: ["LLAMA_API_KEY"],
  source: "models.dev",
  schemaVersion: 1,
  models: {
    "groq-llama-4-maverick-17b-128e-instruct": {
      id: "groq-llama-4-maverick-17b-128e-instruct",
      name: "Groq-Llama-4-Maverick-17B-128E-Instruct",
      attachment: true,
      reasoning: false,
      temperature: true,
      tool_call: true,
      knowledge: "2025-01",
      release_date: "2025-04-05",
      last_updated: "2025-04-05",
      modalities: {
        input: ["text"],
        output: ["text"],
      },
      open_weights: true,
      cost: {
        input: 0,
        output: 0,
      },
      limit: {
        context: 128000,
        output: 4096,
      },
    },
    "llama-3.3-70b-instruct": {
      id: "llama-3.3-70b-instruct",
      name: "Llama-3.3-70B-Instruct",
      attachment: true,
      reasoning: false,
      temperature: true,
      tool_call: true,
      knowledge: "2023-12",
      release_date: "2024-12-06",
      last_updated: "2024-12-06",
      modalities: {
        input: ["text"],
        output: ["text"],
      },
      open_weights: true,
      cost: {
        input: 0,
        output: 0,
      },
      limit: {
        context: 128000,
        output: 4096,
      },
    },
    "llama-4-maverick-17b-128e-instruct-fp8": {
      id: "llama-4-maverick-17b-128e-instruct-fp8",
      name: "Llama-4-Maverick-17B-128E-Instruct-FP8",
      attachment: true,
      reasoning: false,
      temperature: true,
      tool_call: true,
      knowledge: "2024-08",
      release_date: "2025-04-05",
      last_updated: "2025-04-05",
      modalities: {
        input: ["text", "image"],
        output: ["text"],
      },
      open_weights: true,
      cost: {
        input: 0,
        output: 0,
      },
      limit: {
        context: 128000,
        output: 4096,
      },
    },
    "llama-4-scout-17b-16e-instruct-fp8": {
      id: "llama-4-scout-17b-16e-instruct-fp8",
      name: "Llama-4-Scout-17B-16E-Instruct-FP8",
      attachment: true,
      reasoning: false,
      temperature: true,
      tool_call: true,
      knowledge: "2024-08",
      release_date: "2025-04-05",
      last_updated: "2025-04-05",
      modalities: {
        input: ["text", "image"],
        output: ["text"],
      },
      open_weights: true,
      cost: {
        input: 0,
        output: 0,
      },
      limit: {
        context: 128000,
        output: 4096,
      },
    },
    "cerebras-llama-4-scout-17b-16e-instruct": {
      id: "cerebras-llama-4-scout-17b-16e-instruct",
      name: "Cerebras-Llama-4-Scout-17B-16E-Instruct",
      attachment: true,
      reasoning: false,
      temperature: true,
      tool_call: true,
      knowledge: "2025-01",
      release_date: "2025-04-05",
      last_updated: "2025-04-05",
      modalities: {
        input: ["text"],
        output: ["text"],
      },
      open_weights: true,
      cost: {
        input: 0,
        output: 0,
      },
      limit: {
        context: 128000,
        output: 4096,
      },
    },
    "llama-3.3-8b-instruct": {
      id: "llama-3.3-8b-instruct",
      name: "Llama-3.3-8B-Instruct",
      attachment: true,
      reasoning: false,
      temperature: true,
      tool_call: true,
      knowledge: "2023-12",
      release_date: "2024-12-06",
      last_updated: "2024-12-06",
      modalities: {
        input: ["text"],
        output: ["text"],
      },
      open_weights: true,
      cost: {
        input: 0,
        output: 0,
      },
      limit: {
        context: 128000,
        output: 4096,
      },
    },
    "cerebras-llama-4-maverick-17b-128e-instruct": {
      id: "cerebras-llama-4-maverick-17b-128e-instruct",
      name: "Cerebras-Llama-4-Maverick-17B-128E-Instruct",
      attachment: true,
      reasoning: false,
      temperature: true,
      tool_call: true,
      knowledge: "2025-01",
      release_date: "2025-04-05",
      last_updated: "2025-04-05",
      modalities: {
        input: ["text"],
        output: ["text"],
      },
      open_weights: true,
      cost: {
        input: 0,
        output: 0,
      },
      limit: {
        context: 128000,
        output: 4096,
      },
    },
  },
} as const;
export default llamaProvider;
